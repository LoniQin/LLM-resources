# Large Language Models: A Collection of Resources
This repository contains a collection of resources related to large language models (LLMs). LLMs are artificial neural networks that are trained on massive datasets of text, code, and other data. They have been shown to achieve state-of-the-art results on a variety of natural language processing tasks, such as text classification, question answering, and summarization.

## Resources

The resources in this repository includes or will include in the future:
* Jupyter notebooks about LLMs
* Papers and articles about LLMs
* Code and datasets for training and evaluating LLMs
* Examples of LLMs in action

## Notebooks 
1. [Chatbot with Phi-2](chatbot_with_phi2.ipynb)
2. [Chatbot with Mistral-7B-Instruct](Chatbot_with_mistral_7b_instruct.ipynb)
3. [LLM with Mamba](LLM_with_Mamba.ipynb)
4. [Mamba: Linear-Time Sequence Modeling with Selective State Spaces](https://arxiv.org/abs/2312.00752)

## Papers
* [Textbooks Are All You Need II: phi-1.5 technical report](https://arxiv.org/abs/2309.05463)
* [Mistral 7B](https://arxiv.org/pdf/2310.06825v1.pdf)
## Usage

This repository can be used to learn more about LLMs, to get started using LLMs in your own work, and to see examples of what LLMs can do.

## Contributing

We welcome contributions to this repository. If you have any resources related to LLMs that you would like to share, please feel free to submit a pull request.

## License

This repository is licensed under the MIT License.

## Contact

If you have any questions about this repository, please feel free to contact us at lonnieqin1992@gmail.com
